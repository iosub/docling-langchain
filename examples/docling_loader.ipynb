{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/DS4SD/docling/blob/main/docs/examples/rag_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Step | Tech | Execution | \n",
    "| --- | --- | --- |\n",
    "| Embedding | Hugging Face / Sentence Transformers | ðŸ’» Local |\n",
    "| Vector store | Milvus | ðŸ’» Local |\n",
    "| Gen AI | Hugging Face Inference API | ðŸŒ Remote | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example leverages the\n",
    "[LangChain Docling integration](../../integrations/langchain/), along with a Milvus\n",
    "vector store, as well as sentence-transformers embeddings.\n",
    "\n",
    "The presented `DoclingLoader` component enables you to:\n",
    "- use various document types in your LLM applications with ease and speed, and\n",
    "- leverage Docling's rich format for advanced, document-native grounding.\n",
    "\n",
    "`DoclingLoader` supports two different export modes:\n",
    "- `ExportType.MARKDOWN`: if you want to capture each input document as a separate\n",
    "  LangChain document, or\n",
    "- `ExportType.DOC_CHUNKS` (default): if you want to have each input document chunked and\n",
    "  to then capture each individual chunk as a separate LangChain document downstream.\n",
    "\n",
    "The example allows exploring both modes via parameter `EXPORT_TYPE`; depending on the\n",
    "value set, the example pipeline is then set up accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ðŸ‘‰ For best conversion speed, use GPU acceleration whenever available; e.g. if running on Colab, use GPU-enabled runtime.\n",
    "- Notebook uses HuggingFace's Inference API; for increased LLM quota, token can be provided via env var `HF_TOKEN`.\n",
    "- Requirements can be installed as shown below (`--no-warn-conflicts` meant for Colab's pre-populated Python env; feel free to remove for stricter usage):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --progress-bar off --no-warn-conflicts langchain-docling langchain-core langchain-huggingface langchain_milvus langchain python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain_docling.loader import ExportType\n",
    "\n",
    "\n",
    "def _get_env_from_colab_or_os(key):\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "\n",
    "        try:\n",
    "            return userdata.get(key)\n",
    "        except userdata.SecretNotFoundError:\n",
    "            pass\n",
    "    except ImportError:\n",
    "        pass\n",
    "    return os.getenv(key)\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# https://github.com/huggingface/transformers/issues/5486:\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "HF_TOKEN = _get_env_from_colab_or_os(\"HF_TOKEN\")\n",
    "FILE_PATH = [\"https://arxiv.org/pdf/2408.09869\"]  # Docling Technical Report\n",
    "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "GEN_MODEL_ID = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "EXPORT_TYPE = ExportType.DOC_CHUNKS\n",
    "QUESTION = \"Which are the main AI models in Docling?\"\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {input}\\nAnswer:\\n\",\n",
    ")\n",
    "TOP_K = 3\n",
    "MILVUS_URI = str(Path(mkdtemp()) / \"docling.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document loading\n",
    "\n",
    "Now we can instantiate our loader and load documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_docling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DoclingLoader\n\u001b[32m      5\u001b[39m loader = DoclingLoader(\n\u001b[32m      6\u001b[39m     file_path=FILE_PATH,\n\u001b[32m      7\u001b[39m     export_type=EXPORT_TYPE,\n\u001b[32m      8\u001b[39m     chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m docs = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:32\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\langchain_docling\\loader.py:117\u001b[39m, in \u001b[36mDoclingLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Lazy load documents.\"\"\"\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._file_paths:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_converter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     dl_doc = conv_res.document\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._export_type == ExportType.MARKDOWN:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__pydantic_complete__:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\docling\\document_converter.py:220\u001b[39m, in \u001b[36mDocumentConverter.convert\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;129m@validate_call\u001b[39m(config=ConfigDict(strict=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m    204\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    210\u001b[39m     page_range: PageRange = DEFAULT_PAGE_RANGE,\n\u001b[32m    211\u001b[39m ) -> ConversionResult:\n\u001b[32m    212\u001b[39m     all_res = \u001b[38;5;28mself\u001b[39m.convert_all(\n\u001b[32m    213\u001b[39m         source=[source],\n\u001b[32m    214\u001b[39m         raises_on_error=raises_on_error,\n\u001b[32m   (...)\u001b[39m\u001b[32m    218\u001b[39m         page_range=page_range,\n\u001b[32m    219\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\docling\\document_converter.py:243\u001b[39m, in \u001b[36mDocumentConverter.convert_all\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    240\u001b[39m conv_res_iter = \u001b[38;5;28mself\u001b[39m._convert(conv_input, raises_on_error=raises_on_error)\n\u001b[32m    242\u001b[39m had_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhad_result\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPARTIAL_SUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\docling\\document_converter.py:278\u001b[39m, in \u001b[36mDocumentConverter._convert\u001b[39m\u001b[34m(self, conv_input, raises_on_error)\u001b[39m\n\u001b[32m    269\u001b[39m _log.info(\u001b[33m\"\u001b[39m\u001b[33mGoing to convert document batch...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    271\u001b[39m \u001b[38;5;66;03m# parallel processing only within input_batch\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[38;5;66;03m# with ThreadPoolExecutor(\u001b[39;00m\n\u001b[32m    273\u001b[39m \u001b[38;5;66;03m#    max_workers=settings.perf.doc_batch_concurrency\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;66;03m# ) as pool:\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[38;5;66;03m#   yield from pool.map(self.process_document, input_batch)\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# Note: PDF backends are not thread-safe, thread pool usage was disabled.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_document\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43melapsed\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\docling\\document_converter.py:324\u001b[39m, in \u001b[36mDocumentConverter._process_document\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    320\u001b[39m valid = (\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.allowed_formats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m in_doc.format \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.allowed_formats\n\u001b[32m    322\u001b[39m )\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    326\u001b[39m     error_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not allowed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_doc.file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\docling\\document_converter.py:347\u001b[39m, in \u001b[36mDocumentConverter._execute_pipeline\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    345\u001b[39m pipeline = \u001b[38;5;28mself\u001b[39m._get_pipeline(in_doc.format)\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     conv_res = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raises_on_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\docling\\pipeline\\base_pipeline.py:46\u001b[39m, in \u001b[36mBasePipeline.execute\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m TimeRecorder(\n\u001b[32m     42\u001b[39m         conv_res, \u001b[33m\"\u001b[39m\u001b[33mpipeline_total\u001b[39m\u001b[33m\"\u001b[39m, scope=ProfilingScope.DOCUMENT\n\u001b[32m     43\u001b[39m     ):\n\u001b[32m     44\u001b[39m         \u001b[38;5;66;03m# These steps are building and assembling the structure of the\u001b[39;00m\n\u001b[32m     45\u001b[39m         \u001b[38;5;66;03m# output DoclingDocument.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m         conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m         conv_res = \u001b[38;5;28mself\u001b[39m._assemble_document(conv_res)\n\u001b[32m     48\u001b[39m         \u001b[38;5;66;03m# From this stage, all operations should rely only on conv_res.output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\docling\\pipeline\\base_pipeline.py:160\u001b[39m, in \u001b[36mPaginatedPipeline._build_document\u001b[39m\u001b[34m(self, conv_res)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# 2. Run pipeline stages\u001b[39;00m\n\u001b[32m    158\u001b[39m pipeline_pages = \u001b[38;5;28mself\u001b[39m._apply_on_pages(conv_res, init_pages)\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpipeline_pages\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Must exhaust!\u001b[39;49;00m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Cleanup cached images\u001b[39;49;00m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeep_images\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_image_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\docling\\pipeline\\base_pipeline.py:126\u001b[39m, in \u001b[36mPaginatedPipeline._apply_on_pages\u001b[39m\u001b[34m(self, conv_res, page_batch)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.build_pipe:\n\u001b[32m    124\u001b[39m     page_batch = model(conv_res, page_batch)\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m page_batch\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\docling\\models\\page_assemble_model.py:69\u001b[39m, in \u001b[36mPageAssembleModel.__call__\u001b[39m\u001b[34m(self, conv_res, page_batch)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mself\u001b[39m, conv_res: ConversionResult, page_batch: Iterable[Page]\n\u001b[32m     68\u001b[39m ) -> Iterable[Page]:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage_batch\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_valid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\docling\\models\\table_structure_model.py:181\u001b[39m, in \u001b[36mTableStructureModel.__call__\u001b[39m\u001b[34m(self, conv_res, page_batch)\u001b[39m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m page_batch\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage_batch\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_valid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\docling\\models\\layout_model.py:146\u001b[39m, in \u001b[36mLayoutModel.__call__\u001b[39m\u001b[34m(self, conv_res, page_batch)\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    144\u001b[39m     \u001b[38;5;28mself\u001b[39m, conv_res: ConversionResult, page_batch: Iterable[Page]\n\u001b[32m    145\u001b[39m ) -> Iterable[Page]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage_batch\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_valid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\docling\\models\\easyocr_model.py:151\u001b[39m, in \u001b[36mEasyOcrModel.__call__\u001b[39m\u001b[34m(self, conv_res, page_batch)\u001b[39m\n\u001b[32m    147\u001b[39m high_res_image = page._backend.get_page_image(\n\u001b[32m    148\u001b[39m     scale=\u001b[38;5;28mself\u001b[39m.scale, cropbox=ocr_rect\n\u001b[32m    149\u001b[39m )\n\u001b[32m    150\u001b[39m im = numpy.array(high_res_image)\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m high_res_image\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m im\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\easyocr\\easyocr.py:468\u001b[39m, in \u001b[36mReader.readtext\u001b[39m\u001b[34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[39m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[32m    467\u001b[39m horizontal_list, free_list = horizontal_list[\u001b[32m0\u001b[39m], free_list[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_cv_grey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizontal_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfree_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeamWidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocklist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotation_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mparagraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrast_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjust_contrast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mfilter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\easyocr\\easyocr.py:384\u001b[39m, in \u001b[36mReader.recognize\u001b[39m\u001b[34m(self, img_cv_grey, horizontal_list, free_list, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, contrast_ths, adjust_contrast, filter_ths, y_ths, x_ths, reformat, output_format)\u001b[39m\n\u001b[32m    382\u001b[39m     f_list = []\n\u001b[32m    383\u001b[39m     image_list, max_width = get_image_list(h_list, f_list, img_cv_grey, model_height = imgH)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     result0 = \u001b[43mget_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcharacter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mignore_char\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeamWidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrast_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjust_contrast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m     result += result0\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m free_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\easyocr\\recognition.py:218\u001b[39m, in \u001b[36mget_text\u001b[39m\u001b[34m(character, imgH, imgW, recognizer, converter, image_list, ignore_char, decoder, beamWidth, batch_size, contrast_ths, adjust_contrast, filter_ths, workers, device)\u001b[39m\n\u001b[32m    214\u001b[39m     test_data = ListDataset(img_list2)\n\u001b[32m    215\u001b[39m     test_loader = torch.utils.data.DataLoader(\n\u001b[32m    216\u001b[39m                     test_data, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    217\u001b[39m                     num_workers=\u001b[38;5;28mint\u001b[39m(workers), collate_fn=AlignCollate_contrast, pin_memory=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     result2 = \u001b[43mrecognizer_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_max_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mignore_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar_group_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeamWidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m result = []\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, zipped \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(coord, result1)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\easyocr\\recognition.py:111\u001b[39m, in \u001b[36mrecognizer_predict\u001b[39m\u001b[34m(model, converter, test_loader, batch_max_length, ignore_idx, char_group_idx, decoder, beamWidth, device)\u001b[39m\n\u001b[32m    108\u001b[39m length_for_pred = torch.IntTensor([batch_max_length] * batch_size).to(device)\n\u001b[32m    109\u001b[39m text_for_pred = torch.LongTensor(batch_size, batch_max_length + \u001b[32m1\u001b[39m).fill_(\u001b[32m0\u001b[39m).to(device)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m preds = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_for_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Select max probabilty (greedy decoding) then decode index to character\u001b[39;00m\n\u001b[32m    114\u001b[39m preds_size = torch.IntTensor([preds.size(\u001b[32m1\u001b[39m)] * batch_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\easyocr\\model\\vgg_model.py:25\u001b[39m, in \u001b[36mModel.forward\u001b[39m\u001b[34m(self, input, text)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, text):\n\u001b[32m     24\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" Feature extraction stage \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     visual_feature = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mFeatureExtraction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     visual_feature = \u001b[38;5;28mself\u001b[39m.AdaptiveAvgPool(visual_feature.permute(\u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m     27\u001b[39m     visual_feature = visual_feature.squeeze(\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\easyocr\\model\\modules.py:124\u001b[39m, in \u001b[36mVGG_FeatureExtractor.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mConvNet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\IA\\ver2\\tools\\docling-langchain\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from docling.chunking import HybridChunker\n",
    "\n",
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "loader = DoclingLoader(\n",
    "    file_path=FILE_PATH,\n",
    "    export_type=EXPORT_TYPE,\n",
    "    chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPORT_TYPE == ExportType.DOC_CHUNKS:\n",
    "    splits = docs\n",
    "elif EXPORT_TYPE == ExportType.MARKDOWN:\n",
    "    from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "    splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=[\n",
    "            (\"#\", \"Header_1\"),\n",
    "            (\"##\", \"Header_2\"),\n",
    "            (\"###\", \"Header_3\"),\n",
    "        ],\n",
    "    )\n",
    "    splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting some sample splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- d.page_content='arXiv:2408.09869v5  [cs.CL]  9 Dec 2024'\n",
      "- d.page_content='Docling Technical Report\\nVersion 1.0\\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\\nAI4K Group, IBM Research RÂ¨uschlikon, Switzerland'\n",
      "- d.page_content='Abstract\\nThis technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.'\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "for d in splits[:3]:\n",
    "    print(f\"- {d.page_content=}\")\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_milvus import Milvus\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(model_name=EMBED_MODEL_ID)\n",
    "\n",
    "\n",
    "milvus_uri = str(Path(mkdtemp()) / \"docling.db\")  # or set as needed\n",
    "vectorstore = Milvus.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    collection_name=\"docling_demo\",\n",
    "    connection_args={\"uri\": milvus_uri},\n",
    "    index_params={\"index_type\": \"FLAT\"},\n",
    "    drop_old=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=GEN_MODEL_ID,\n",
    "    huggingfacehub_api_token=HF_TOKEN,\n",
    ")\n",
    "\n",
    "\n",
    "def clip_text(text, threshold=100):\n",
    "    return f\"{text[:threshold]}...\" if len(text) > threshold else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Which are the main AI models in Docling?\n",
      "\n",
      "Answer:\n",
      "Docling currently supports two main AI models, namely a layout analysis model and a table structure recognition model. The first model is a layout analysis model, an accurate object-detector for page ...\n",
      "\n",
      "Source 1:\n",
      "  text: \"3.2 AI models\\nAs part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure re...\"\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/50', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 108.0, 't': 405.1419982910156, 'r': 504.00299072265625, 'b': 330.7799987792969, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 608]}]}], 'headings': ['3.2 AI models'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
      "  source: https://arxiv.org/pdf/2408.09869\n",
      "\n",
      "Source 2:\n",
      "  text: \"3 Processing pipeline\\nDocling implements a linear pipeline of operations, which execute sequentially on each given document (see Fig. 1). Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support ...\"\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/26', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 108.0, 't': 273.01800537109375, 'r': 504.00299072265625, 'b': 176.83799743652344, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 796]}]}], 'headings': ['3 Processing pipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
      "  source: https://arxiv.org/pdf/2408.09869\n",
      "\n",
      "Source 3:\n",
      "  text: \"6 Future work and contributions\\nDocling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of ...\"\n",
      "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/76', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 322.468994140625, 'r': 504.00299072265625, 'b': 259.0169982910156, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 543]}]}, {'self_ref': '#/texts/77', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 251.6540069580078, 'r': 504.00299072265625, 'b': 198.99200439453125, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 402]}]}], 'headings': ['6 Future work and contributions'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
      "  source: https://arxiv.org/pdf/2408.09869\n"
     ]
    }
   ],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "resp_dict = rag_chain.invoke({\"input\": QUESTION})\n",
    "\n",
    "clipped_answer = clip_text(resp_dict[\"answer\"], threshold=200)\n",
    "print(f\"Question:\\n{resp_dict['input']}\\n\\nAnswer:\\n{clipped_answer}\")\n",
    "for i, doc in enumerate(resp_dict[\"context\"]):\n",
    "    print()\n",
    "    print(f\"Source {i+1}:\")\n",
    "    print(f\"  text: {json.dumps(clip_text(doc.page_content, threshold=350))}\")\n",
    "    for key in doc.metadata:\n",
    "        if key != \"pk\":\n",
    "            val = doc.metadata.get(key)\n",
    "            clipped_val = clip_text(val) if isinstance(val, str) else val\n",
    "            print(f\"  {key}: {clipped_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
